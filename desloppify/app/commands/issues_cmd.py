"""issues command: state-backed work queue for review findings."""

from __future__ import annotations

import argparse
import sys
from pathlib import Path

from desloppify.app.commands.helpers.lang import resolve_lang
from desloppify.app.commands.helpers.query import write_query
from desloppify.app.commands.helpers.rendering import print_agent_plan
from desloppify.app.commands.helpers.runtime import command_runtime
from desloppify.core.issues_render import finding_weight, render_issue_detail
from desloppify.engine.work_queue import (
    impact_label,
    list_open_review_findings,
    update_investigation,
)
from desloppify.intelligence.narrative import NarrativeContext, compute_narrative
from desloppify.state import save_state, utc_now
from desloppify.utils import colorize


def cmd_issues(args: argparse.Namespace) -> None:
    """Dispatch to list/show/update based on subcommand."""
    action = getattr(args, "issues_action", None)
    if action in (None, "list"):
        _list_issues(args)
    elif action == "show":
        _show_issue(args)
    elif action == "update":
        _update_issue(args)
    elif action == "merge":
        _merge_issues(args)


def _word_set(text: str) -> set[str]:
    words = "".join(ch.lower() if ch.isalnum() else " " for ch in text).split()
    return {word for word in words if len(word) >= 3}


def _summary_similarity(a: str, b: str) -> float:
    left = _word_set(a)
    right = _word_set(b)
    if not left or not right:
        return 0.0
    overlap = len(left & right)
    union = len(left | right)
    return float(overlap) / float(union) if union else 0.0


def _parse_holistic_identifier(finding_id: str) -> str:
    parts = [part for part in str(finding_id).split("::") if part]
    if len(parts) < 2:
        return ""
    candidate = parts[-2].strip()
    if not candidate or candidate in {"holistic", "changed", "stale", "unreviewed"}:
        return ""
    return candidate


def _related_files_set(finding: dict) -> set[str]:
    related = finding.get("detail", {}).get("related_files", [])
    if not isinstance(related, list):
        return set()
    return {str(path).strip() for path in related if str(path).strip()}


def _same_issue_concept(
    left: dict,
    right: dict,
    *,
    similarity_threshold: float,
) -> bool:
    left_detail = left.get("detail", {})
    right_detail = right.get("detail", {})
    if left_detail.get("dimension") != right_detail.get("dimension"):
        return False

    left_identifier = _parse_holistic_identifier(left.get("id", ""))
    right_identifier = _parse_holistic_identifier(right.get("id", ""))
    if left_identifier and right_identifier and left_identifier == right_identifier:
        return True

    left_summary = str(left.get("summary", "")).strip()
    right_summary = str(right.get("summary", "")).strip()
    similarity = _summary_similarity(left_summary, right_summary)
    if similarity < similarity_threshold:
        return False

    left_files = _related_files_set(left)
    right_files = _related_files_set(right)
    if left_files and right_files and not (left_files & right_files):
        return False
    return True


def _merge_finding_details(primary: dict, duplicate: dict) -> None:
    primary_detail = primary.setdefault("detail", {})
    duplicate_detail = duplicate.get("detail", {})

    for field in ("related_files", "evidence"):
        merged: list[str] = []
        seen: set[str] = set()
        for source in (primary_detail.get(field), duplicate_detail.get(field)):
            if not isinstance(source, list):
                continue
            for item in source:
                value = str(item).strip()
                if not value or value in seen:
                    continue
                seen.add(value)
                merged.append(value)
        if merged:
            primary_detail[field] = merged

    primary_suggestion = str(primary_detail.get("suggestion", "")).strip()
    duplicate_suggestion = str(duplicate_detail.get("suggestion", "")).strip()
    if len(duplicate_suggestion) > len(primary_suggestion):
        primary_detail["suggestion"] = duplicate_suggestion

    merged_from = primary_detail.get("merged_from")
    if not isinstance(merged_from, list):
        merged_from = []
    duplicate_id = duplicate.get("id", "")
    if duplicate_id and duplicate_id not in merged_from:
        merged_from.append(duplicate_id)
    if merged_from:
        primary_detail["merged_from"] = merged_from


def _score_for_issue(finding, assessments, weight_fn, label_fn) -> str:
    """Render score cell as '<assessment> <impact>'."""
    dim = finding.get("detail", {}).get("dimension", "")
    raw_score = assessments.get(dim)
    score = f"{float(raw_score):.1f}" if isinstance(raw_score, int | float) else "--.-"
    weight, _, _ = weight_fn(finding)
    return f"{score} {label_fn(weight)}"


def _list_issues(args):
    """Print numbered table of open review findings."""
    state = command_runtime(args).state
    narrative = compute_narrative(state, context=NarrativeContext(command="issues"))
    items = list_open_review_findings(state)

    if not items:
        print(colorize("\n  No review findings open.\n", "dim"))
        print(
            colorize(
                "  Next command: `desloppify review --prepare`",
                "dim",
            )
        )
        print()
        write_query(
            {
                "command": "issues",
                "action": "list",
                "items": [],
                "next_command": "desloppify review --prepare",
                "narrative": narrative,
            }
        )
        return

    print(
        colorize(
            f"\n  {len(items)} open review finding{'s' if len(items) != 1 else ''} "
            f"(highest impact first)\n",
            "bold",
        )
    )

    assessments = state.get("subjective_assessments") or {}
    # Table header
    print(f"  {'#':<4} {'Score':<8} {'Dimension':<28} {'Summary':<50} {'Investigated'}")
    print(f"  {'─' * 4} {'─' * 8} {'─' * 28} {'─' * 50} {'─' * 12}")

    for i, f in enumerate(items, 1):
        score_str = _score_for_issue(f, assessments, finding_weight, impact_label)
        dim = f.get("detail", {}).get("dimension", "unknown").replace("_", " ")
        summary = f.get("summary", "")[:50]
        investigated = "yes" if f.get("detail", {}).get("investigation") else "no"
        print(f"  {i:<4} {score_str:<8} {dim:<28} {summary:<50} {investigated}")

    uninvestigated = sum(
        1 for f in items if not f.get("detail", {}).get("investigation")
    )
    print()
    if uninvestigated:
        print(colorize(f"  {uninvestigated} need investigation.", "dim"))
    print_agent_plan(
        [
            "Read one issue deeply: `desloppify issues show 1`",
            "Add investigation notes: `desloppify issues update 1 --file analysis.md`",
            "Fix and resolve the finding",
        ],
        next_command="desloppify issues show 1",
    )
    print()

    write_query(
        {
            "command": "issues",
            "action": "list",
            "count": len(items),
            "items": [
                {
                    "id": f["id"],
                    "summary": f.get("summary", ""),
                    "dimension": f.get("detail", {}).get("dimension", ""),
                    "investigated": bool(f.get("detail", {}).get("investigation")),
                }
                for f in items
            ],
            "next_command": "desloppify issues show 1",
            "narrative": narrative,
        }
    )


def _show_issue(args):
    """Show full details for a single issue by number."""
    state = command_runtime(args).state
    narrative = compute_narrative(state, context=NarrativeContext(command="issues"))
    items = list_open_review_findings(state)
    number = args.number

    if not items:
        print(colorize("\n  No review findings open.\n", "dim"))
        return

    if number < 1 or number > len(items):
        print(
            colorize(f"\n  Issue #{number} out of range (1–{len(items)}).\n", "red"),
            file=sys.stderr,
        )
        return

    finding = items[number - 1]
    lang = resolve_lang(args)
    lang_name = lang.name if lang else finding.get("lang", "unknown")

    assessments = state.get("subjective_assessments") or {}
    doc = render_issue_detail(
        finding, lang_name, number=number, subjective_assessments=assessments
    )
    print()
    print(doc)

    write_query(
        {
            "command": "issues",
            "action": "show",
            "number": number,
            "finding": {
                "id": finding["id"],
                "summary": finding.get("summary", ""),
                "detail": finding.get("detail", {}),
            },
            "next_command": f'desloppify resolve fixed "{finding["id"]}" --note "<what you fixed>"',
            "narrative": narrative,
        }
    )


def _update_issue(args):
    """Add investigation notes to an issue."""
    runtime = command_runtime(args)
    state = runtime.state
    state_file = runtime.state_path
    narrative = compute_narrative(state, context=NarrativeContext(command="issues"))
    items = list_open_review_findings(state)
    number = args.number

    if not items:
        print(colorize("\n  No review findings open.\n", "dim"))
        return

    if number < 1 or number > len(items):
        print(
            colorize(f"\n  Issue #{number} out of range (1–{len(items)}).\n", "red"),
            file=sys.stderr,
        )
        return

    finding = items[number - 1]
    file_path = Path(args.file)
    if not file_path.exists():
        print(colorize(f"\n  File not found: {args.file}\n", "red"), file=sys.stderr)
        return

    try:
        text = file_path.read_text()
    except OSError as e:
        print(colorize(f"\n  Could not read file: {e}\n", "red"), file=sys.stderr)
        return

    ok = update_investigation(state, finding["id"], text)
    if not ok:
        print(
            colorize(f"\n  Could not update issue #{number}.\n", "red"), file=sys.stderr
        )
        return

    save_state(state, state_file)
    lang = resolve_lang(args)
    lang_name = lang.name if lang else finding.get("lang", "unknown")
    print(colorize(f"\n  Investigation saved for issue #{number}.", "green"))
    print(
        colorize(
            f'  Fix the issue, then: desloppify --lang {lang_name} resolve fixed "{finding["id"]}"',
            "dim",
        )
    )
    print(colorize("  Next command: `desloppify issues show 1`", "dim"))
    print()
    write_query(
        {
            "command": "issues",
            "action": "update",
            "number": number,
            "finding_id": finding["id"],
            "next_command": f'desloppify --lang {lang_name} resolve fixed "{finding["id"]}"',
            "narrative": narrative,
        }
    )


def _merge_issues(args):
    """Merge conceptually duplicate open review findings."""
    runtime = command_runtime(args)
    state = runtime.state
    state_file = runtime.state_path
    narrative = compute_narrative(state, context=NarrativeContext(command="issues"))
    items = list_open_review_findings(state)

    if not items:
        print(colorize("\n  No review findings open.\n", "dim"))
        return

    try:
        similarity = float(getattr(args, "similarity", 0.8))
    except (TypeError, ValueError):
        similarity = 0.8
    similarity = max(0.0, min(1.0, similarity))

    open_holistic = [
        finding
        for finding in items
        if finding.get("detector") == "review"
        and finding.get("detail", {}).get("holistic")
    ]
    if len(open_holistic) < 2:
        print(colorize("\n  Not enough holistic review findings to merge.\n", "dim"))
        return

    consumed: set[str] = set()
    merge_groups: list[list[dict]] = []
    for candidate in open_holistic:
        candidate_id = candidate.get("id", "")
        if not candidate_id or candidate_id in consumed:
            continue
        group = [candidate]
        consumed.add(candidate_id)
        for other in open_holistic:
            other_id = other.get("id", "")
            if not other_id or other_id in consumed:
                continue
            if _same_issue_concept(
                candidate,
                other,
                similarity_threshold=similarity,
            ):
                consumed.add(other_id)
                group.append(other)
        if len(group) > 1:
            merge_groups.append(group)

    if not merge_groups:
        print(
            colorize(
                "\n  No duplicate issue concepts found at the current similarity threshold.\n",
                "dim",
            )
        )
        return

    dry_run = bool(getattr(args, "dry_run", False))
    timestamp = utc_now()
    merged_pairs: list[tuple[str, list[str]]] = []
    for group in merge_groups:
        ranked = sorted(
            group,
            key=lambda finding: (finding_weight(finding)[0], finding.get("id", "")),
            reverse=True,
        )
        primary = ranked[0]
        duplicates = ranked[1:]
        merged_pairs.append((primary.get("id", ""), [d.get("id", "") for d in duplicates]))
        if dry_run:
            continue
        for duplicate in duplicates:
            _merge_finding_details(primary, duplicate)
            duplicate["status"] = "auto_resolved"
            duplicate["resolved_at"] = timestamp
            duplicate["note"] = f"merged into {primary.get('id', '')}"
            duplicate["resolution_attestation"] = {
                "kind": "issue_merge",
                "text": "Merged conceptually duplicate review finding",
                "attested_at": timestamp,
                "scan_verified": False,
            }
        primary_detail = primary.setdefault("detail", {})
        primary_detail["merged_at"] = timestamp

    print(
        colorize(
            f"\n  Merge groups: {len(merge_groups)} | "
            f"duplicate findings: {sum(len(group) - 1 for group in merge_groups)}",
            "bold",
        )
    )
    for index, (primary_id, duplicate_ids) in enumerate(merged_pairs, 1):
        preview = ", ".join(duplicate_ids[:3])
        if len(duplicate_ids) > 3:
            preview = f"{preview}, +{len(duplicate_ids) - 3} more"
        print(colorize(f"  [{index}] keep {primary_id}", "dim"))
        print(colorize(f"      merge {preview}", "dim"))

    if dry_run:
        print(colorize("\n  Dry run only: no state changes written.\n", "yellow"))
        return

    save_state(state, state_file)
    print(colorize("\n  State updated with merged issue groups.\n", "green"))
    write_query(
        {
            "command": "issues",
            "action": "merge",
            "groups": len(merge_groups),
            "duplicates_merged": sum(len(group) - 1 for group in merge_groups),
            "next_command": "desloppify issues",
            "narrative": narrative,
        }
    )
