"""Multi-line smell detection helpers (brace-tracked).

Extracted from smells.py to keep file sizes manageable.
All helpers are imported into smells.py for use in detect_smells().
"""

import re

_MAX_CATCH_BODY = 1000  # max characters to scan for catch block body


def _scan_code(text: str, start: int = 0, end: int | None = None):
    """Yield (index, char, in_string) tuples, handling escapes correctly.

    Skips escaped characters (\\x) by advancing +2 instead of +1.
    Tracks single-quoted, double-quoted, and template literal strings.
    Correct for \\\\\" (escaped backslash before quote) where prev_ch pattern fails.
    """
    i = start
    limit = end if end is not None else len(text)
    in_str = None
    while i < limit:
        ch = text[i]
        if in_str:
            if ch == '\\' and i + 1 < limit:
                yield (i, ch, True)
                i += 1
                yield (i, text[i], True)
                i += 1
                continue
            if ch == in_str:
                in_str = None
            yield (i, ch, in_str is not None)
        else:
            if ch in ("'", '"', '`'):
                in_str = ch
                yield (i, ch, True)
            else:
                yield (i, ch, False)
        i += 1


def _strip_ts_comments(text: str) -> str:
    """Strip // and /* */ comments while preserving strings."""
    result: list[str] = []
    i = 0
    in_str = None
    while i < len(text):
        ch = text[i]
        if in_str:
            if ch == '\\' and i + 1 < len(text):
                result.append(text[i:i + 2])
                i += 2
                continue
            if ch == in_str:
                in_str = None
            result.append(ch)
            i += 1
        elif ch in ('"', "'", '`'):
            in_str = ch
            result.append(ch)
            i += 1
        elif ch == '/' and i + 1 < len(text):
            if text[i + 1] == '/':
                nl = text.find('\n', i)
                if nl == -1:
                    break
                i = nl
            elif text[i + 1] == '*':
                end = text.find('*/', i + 2)
                if end == -1:
                    break
                i = end + 2
            else:
                result.append(ch)
                i += 1
        else:
            result.append(ch)
            i += 1
    return ''.join(result)


def _ts_match_is_in_string(line: str, match_start: int) -> bool:
    """Check if a match position falls inside a string literal or comment on a single line.

    Mirrors Python's _match_is_in_string but for TS syntax (', ", `, //).
    """
    i = 0
    in_str = None

    while i < len(line):
        if i == match_start:
            return in_str is not None

        ch = line[i]

        # Escape sequences inside strings
        if in_str and ch == "\\" and i + 1 < len(line):
            i += 2
            continue

        if in_str:
            if ch == in_str:
                in_str = None
            i += 1
            continue

        # Line comment — everything after is non-code
        if ch == "/" and i + 1 < len(line) and line[i + 1] == "/":
            return match_start > i

        if ch in ("'", '"', '`'):
            in_str = ch
            i += 1
            continue

        i += 1

    return False


def _detect_async_no_await(filepath: str, content: str, lines: list[str],
                           smell_counts: dict[str, list[dict]]):
    """Find async functions that don't use await.

    Algorithm: for each async declaration, track brace depth to find the function
    body extent (up to 200 lines). Scan each line for 'await' within those braces.
    If the opening brace closes (depth returns to 0) without seeing await, flag it.
    """
    async_re = re.compile(r"(?:async\s+function\s+(\w+)|(\w+)\s*=\s*async)")
    for i, line in enumerate(lines):
        m = async_re.search(line)
        if not m:
            continue
        name = m.group(1) or m.group(2)
        brace_depth = 0
        found_open = False
        has_await = False
        for j in range(i, min(i + 200, len(lines))):
            body_line = lines[j]
            prev_code_ch = ""
            for _, ch, in_s in _scan_code(body_line):
                if in_s:
                    continue
                if ch == '/' and prev_code_ch == '/':
                    break  # Rest of line is comment
                elif ch == '{':
                    brace_depth += 1
                    found_open = True
                elif ch == '}':
                    brace_depth -= 1
                prev_code_ch = ch
            if "await " in body_line or "await\n" in body_line:
                has_await = True
            if found_open and brace_depth <= 0:
                break

        if found_open and not has_await:
            smell_counts["async_no_await"].append({
                "file": filepath,
                "line": i + 1,
                "content": f"async {name or '(anonymous)'} has no await",
            })


def _detect_error_no_throw(filepath: str, lines: list[str],
                           smell_counts: dict[str, list[dict]]):
    """Find console.error calls not followed by throw or return."""
    for i, line in enumerate(lines):
        if "console.error" in line:
            following = "\n".join(lines[i+1:i+4])
            if not re.search(r"\b(?:throw|return)\b", following):
                smell_counts["console_error_no_throw"].append({
                    "file": filepath,
                    "line": i + 1,
                    "content": line.strip()[:100],
                })


def _detect_empty_if_chains(filepath: str, lines: list[str],
                            smell_counts: dict[str, list[dict]]):
    """Find if/else chains where all branches are empty."""
    i = 0
    while i < len(lines):
        stripped = lines[i].strip()
        if not re.match(r"(?:else\s+)?if\s*\(", stripped):
            i += 1
            continue

        # Single-line: if (...) { }
        if re.match(r"(?:else\s+)?if\s*\([^)]*\)\s*\{\s*\}\s*$", stripped):
            chain_start = i
            j = i + 1
            while j < len(lines):
                next_stripped = lines[j].strip()
                if re.match(r"else\s+if\s*\([^)]*\)\s*\{\s*\}\s*$", next_stripped):
                    j += 1
                    continue
                if re.match(r"(?:\}\s*)?else\s*\{\s*\}\s*$", next_stripped):
                    j += 1
                    continue
                break
            smell_counts["empty_if_chain"].append({
                "file": filepath,
                "line": chain_start + 1,
                "content": stripped[:100],
            })
            i = j
            continue

        # Multi-line: if (...) { followed by } on next non-blank line
        if re.match(r"(?:else\s+)?if\s*\([^)]*\)\s*\{\s*$", stripped):
            chain_start = i
            chain_all_empty = True
            j = i
            while j < len(lines):
                cur = lines[j].strip()
                if j == chain_start:
                    if not re.match(r"(?:else\s+)?if\s*\([^)]*\)\s*\{\s*$", cur):
                        chain_all_empty = False
                        break
                elif re.match(r"\}\s*else\s+if\s*\([^)]*\)\s*\{\s*$", cur):
                    pass
                elif re.match(r"\}\s*else\s*\{\s*$", cur):
                    pass
                elif cur == "}":
                    k = j + 1
                    while k < len(lines) and lines[k].strip() == "":
                        k += 1
                    if k < len(lines) and re.match(r"else\s", lines[k].strip()):
                        j = k
                        continue
                    j += 1
                    break
                elif cur == "":
                    j += 1
                    continue
                else:
                    chain_all_empty = False
                    break
                j += 1

            if chain_all_empty and j > chain_start + 1:
                smell_counts["empty_if_chain"].append({
                    "file": filepath,
                    "line": chain_start + 1,
                    "content": lines[chain_start].strip()[:100],
                })
            i = max(i + 1, j)
            continue

        i += 1


def _detect_dead_useeffects(filepath: str, lines: list[str],
                            smell_counts: dict[str, list[dict]]):
    """Find useEffect calls with empty or whitespace/comment-only bodies.

    Algorithm: two-pass brace/paren tracking with string-escape awareness.
    Pass 1: track paren depth to find the full useEffect(...) extent.
    Pass 2: within that extent, find the arrow body ({...} after =>) using
    brace depth, skipping characters inside string literals (', ", `).
    Then strip comments from the body and check if anything remains.
    """
    for i, line in enumerate(lines):
        stripped = line.strip()
        if not re.match(r"(?:React\.)?useEffect\s*\(\s*\(\s*\)\s*=>\s*\{", stripped):
            continue

        paren_depth = 0
        brace_depth = 0
        end = None
        for j in range(i, min(i + 30, len(lines))):
            for _, ch, in_s in _scan_code(lines[j]):
                if in_s:
                    continue
                if ch == "(":
                    paren_depth += 1
                elif ch == ")":
                    paren_depth -= 1
                    if paren_depth <= 0:
                        end = j
                        break
                elif ch == "{":
                    brace_depth += 1
                elif ch == "}":
                    brace_depth -= 1
            if end is not None:
                break

        if end is None:
            continue

        text = "\n".join(lines[i:end + 1])
        arrow_pos = text.find("=>")
        if arrow_pos == -1:
            continue
        brace_pos = text.find("{", arrow_pos)
        if brace_pos == -1:
            continue

        depth = 0
        body_end = None
        for ci, ch, in_s in _scan_code(text, brace_pos):
            if in_s:
                continue
            if ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
                if depth == 0:
                    body_end = ci
                    break

        if body_end is None:
            continue

        body = text[brace_pos + 1:body_end]
        body_stripped = _strip_ts_comments(body)
        if body_stripped.strip() == "":
            smell_counts["dead_useeffect"].append({
                "file": filepath,
                "line": i + 1,
                "content": stripped[:100],
            })


def _detect_swallowed_errors(filepath: str, content: str, lines: list[str],
                              smell_counts: dict[str, list[dict]]):
    """Find catch blocks whose only content is console.error/warn/log (swallowed errors).

    Algorithm: regex-find each `catch(...) {`, then track brace depth with
    string-escape awareness to extract the catch body (up to 500 chars).
    Strip comments, split into statements, and check if every statement
    is a console.error/warn/log call.
    """
    catch_re = re.compile(r"catch\s*\([^)]*\)\s*\{")
    for m in catch_re.finditer(content):
        brace_start = m.end() - 1
        depth = 0
        body_end = None
        for ci, ch, in_s in _scan_code(content, brace_start, min(brace_start + 500, len(content))):
            if in_s:
                continue
            if ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
                if depth == 0:
                    body_end = ci
                    break

        if body_end is None:
            continue

        body = content[brace_start + 1:body_end]
        body_clean = _strip_ts_comments(body).strip()

        if not body_clean:
            continue  # empty catch — caught by empty_catch detector

        statements = [s.strip().rstrip(";") for s in re.split(r"[;\n]", body_clean) if s.strip()]
        if not statements:
            continue

        all_console = all(
            re.match(r"console\.(error|warn|log)\s*\(", stmt)
            for stmt in statements
        )
        if all_console:
            line_no = content[:m.start()].count("\n") + 1
            smell_counts["swallowed_error"].append({
                "file": filepath,
                "line": line_no,
                "content": lines[line_no - 1].strip()[:100] if line_no <= len(lines) else "",
            })


def _track_brace_body(lines: list[str], start_line: int, *, max_scan: int = 2000) -> int | None:
    """Find the closing brace that matches the first opening brace from start_line.

    Tracks brace depth with string-literal awareness (', ", `).
    Returns the line index of the closing brace, or None if not found.
    """
    depth = 0
    found_open = False
    for j in range(start_line, min(start_line + max_scan, len(lines))):
        for _, ch, in_s in _scan_code(lines[j]):
            if in_s:
                continue
            if ch == "{":
                depth += 1
                found_open = True
            elif ch == "}":
                depth -= 1
                if found_open and depth == 0:
                    return j
    return None


def _find_function_start(line: str, next_lines: list[str]) -> str | None:
    """Return the function name if this line starts a named function, else None.

    Matches:
    - function foo(...)
    - export function foo(...)
    - export default function foo(...)
    - const foo = (...) => {
    - const foo = async (...) => {
    - const foo = function(...)

    Skips interfaces, types, enums, classes.
    """
    stripped = line.strip()
    if re.match(r"(?:export\s+)?(?:interface|type|enum|class)\s+", stripped):
        return None

    # function declaration
    m = re.match(
        r"(?:export\s+)?(?:default\s+)?(?:async\s+)?function\s+(\w+)\s*\(",
        stripped,
    )
    if m:
        return m.group(1)

    # const/let/var assignment — need to verify it's actually a function
    m = re.match(r"(?:export\s+)?(?:const|let|var)\s+(\w+)", stripped)
    if not m:
        return None
    name = m.group(1)

    # Look at what follows the = sign
    combined = "\n".join([stripped] + [l.strip() for l in next_lines[:2]])
    eq_pos = combined.find("=", m.end())
    if eq_pos == -1:
        return None
    after_eq = combined[eq_pos + 1:].lstrip()

    # Direct function: must start with (, async, or function keyword.
    # Skips function calls like useMemo(...), useRef(...), React.memo(...) that
    # may contain => in their arguments or type annotations.
    if re.match(r"(?:async|function)\b", after_eq):
        return name
    if after_eq.startswith("("):
        # Check that this ( ... ) is followed by => (arrow function params)
        # not just a function call like someFunction(...)
        brace_pos = combined.find("{", eq_pos)
        segment = combined[eq_pos:brace_pos] if brace_pos != -1 else combined[eq_pos:]
        if "=>" in segment:
            return name
    return None


def _detect_monster_functions(filepath: str, lines: list[str],
                              smell_counts: dict[str, list[dict]]):
    """Find functions/components exceeding 150 LOC via brace-tracking.

    Matches: function declarations, named arrow functions, and React components.
    Skips: interfaces, types, enums, and objects/arrays.
    """
    for i, line in enumerate(lines):
        name = _find_function_start(line, lines[i + 1:i + 3])
        if not name:
            continue

        # Find opening brace on this or next few lines
        brace_line = None
        for k in range(i, min(i + 5, len(lines))):
            if "{" in lines[k]:
                brace_line = k
                break
        if brace_line is None:
            continue

        end_line = _track_brace_body(lines, brace_line, max_scan=2000)
        if end_line is not None:
            loc = end_line - i + 1
            if loc > 150:
                smell_counts["monster_function"].append({
                    "file": filepath,
                    "line": i + 1,
                    "content": f"{name}() — {loc} LOC",
                })


def _detect_dead_functions(filepath: str, lines: list[str],
                           smell_counts: dict[str, list[dict]]):
    """Find functions with empty body or only return/return null.

    Matches function declarations and named arrow functions.
    Skips decorated functions (TS decorators on line above).
    """
    for i, line in enumerate(lines):
        # Skip decorated functions
        if i > 0 and lines[i - 1].strip().startswith("@"):
            continue

        name = _find_function_start(line, lines[i + 1:i + 3])
        if not name:
            continue

        # Find opening brace
        brace_line = None
        for k in range(i, min(i + 5, len(lines))):
            if "{" in lines[k]:
                brace_line = k
                break
        if brace_line is None:
            continue

        end_line = _track_brace_body(lines, brace_line, max_scan=30)
        if end_line is None:
            continue

        # Extract body between braces
        body_text = "\n".join(lines[brace_line:end_line + 1])
        first_brace = body_text.find("{")
        last_brace = body_text.rfind("}")
        if first_brace == -1 or last_brace == -1 or first_brace >= last_brace:
            continue

        body = body_text[first_brace + 1:last_brace]
        body_clean = _strip_ts_comments(body).strip().rstrip(";")

        if body_clean in ("", "return", "return null", "return undefined"):
            label = body_clean or "empty"
            smell_counts["dead_function"].append({
                "file": filepath,
                "line": i + 1,
                "content": f"{name}() — body is {label}",
            })


def _detect_window_globals(filepath: str, lines: list[str],
                           line_state: dict[int, str],
                           smell_counts: dict[str, list[dict]]):
    """Find window.__* assignments — global state escape hatches.

    Matches:
    - window.__foo = ...
    - (window as any).__foo = ...
    - window['__foo'] = ...
    """
    window_re = re.compile(
        r"""(?:"""
        r"""\(?\s*window\s+as\s+any\s*\)?\s*\.\s*(__\w+)"""   # (window as any).__name
        r"""|window\s*\.\s*(__\w+)"""                           # window.__name
        r"""|window\s*\[\s*['"](__\w+)['"]\s*\]"""              # window['__name']
        r""")\s*=""",
    )
    for i, line in enumerate(lines):
        if i in line_state:
            continue
        m = window_re.search(line)
        if not m:
            continue
        if _ts_match_is_in_string(line, m.start()):
            continue
        smell_counts["window_global"].append({
            "file": filepath,
            "line": i + 1,
            "content": line.strip()[:100],
        })


def _detect_catch_return_default(filepath: str, content: str,
                                  smell_counts: dict[str, list[dict]]):
    """Find catch blocks that return object literals with default/no-op values.

    Catches the pattern:
      catch (...) { ... return { key: false, key: null, key: () => {} }; }

    This is a silent failure — the caller gets valid-looking data but the
    operation actually failed.
    """
    catch_re = re.compile(r"catch\s*\([^)]*\)\s*\{")
    for m in catch_re.finditer(content):
        brace_start = m.end() - 1
        depth = 0
        body_end = None
        for ci, ch, in_s in _scan_code(content, brace_start, min(brace_start + _MAX_CATCH_BODY, len(content))):
            if in_s:
                continue
            if ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
                if depth == 0:
                    body_end = ci
                    break

        if body_end is None:
            continue

        body = content[brace_start + 1:body_end]
        # Check if body contains "return {" — a return with object literal
        return_obj = re.search(r"\breturn\s*\{", body)
        if not return_obj:
            continue

        # Extract the returned object content
        obj_start = body.find("{", return_obj.start())
        obj_depth = 0
        obj_end = None
        for ci, ch, in_s in _scan_code(body, obj_start):
            if in_s:
                continue
            if ch == "{":
                obj_depth += 1
            elif ch == "}":
                obj_depth -= 1
                if obj_depth == 0:
                    obj_end = ci
                    break

        if obj_end is None:
            continue

        obj_content = body[obj_start + 1:obj_end]
        # Count default/no-op fields
        noop_count = len(re.findall(r"\(\)\s*=>\s*\{\s*\}", obj_content))  # () => {}
        false_count = len(re.findall(r":\s*(?:false|null|undefined|0|''|\"\")\b", obj_content))
        default_fields = noop_count + false_count

        if default_fields >= 2:
            line_no = content[:m.start()].count("\n") + 1
            # Use content slice to get the line without re-splitting entire file
            line_start = content.rfind("\n", 0, m.start()) + 1
            line_end = content.find("\n", m.start())
            if line_end == -1:
                line_end = len(content)
            smell_counts["catch_return_default"].append({
                "file": filepath,
                "line": line_no,
                "content": content[line_start:line_end].strip()[:100],
            })


def _detect_switch_no_default(filepath: str, content: str,
                               smell_counts: dict[str, list[dict]]):
    """Flag switch statements that have no default case."""
    switch_re = re.compile(r"\bswitch\s*\([^)]*\)\s*\{")
    for m in switch_re.finditer(content):
        brace_start = m.end() - 1
        depth = 0
        body_end = None
        for ci, ch, in_s in _scan_code(content, brace_start, min(brace_start + 5000, len(content))):
            if in_s:
                continue
            if ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
                if depth == 0:
                    body_end = ci
                    break

        if body_end is None:
            continue

        body = content[brace_start + 1:body_end]
        # Count case labels — only flag if there are actual cases
        case_count = len(re.findall(r"\bcase\s+", body))
        if case_count < 2:
            continue

        # Check for default: anywhere in the switch body
        if re.search(r"\bdefault\s*:", body):
            continue

        line_no = content[:m.start()].count("\n") + 1
        line_start = content.rfind("\n", 0, m.start()) + 1
        line_end = content.find("\n", m.start())
        if line_end == -1:
            line_end = len(content)
        smell_counts["switch_no_default"].append({
            "file": filepath,
            "line": line_no,
            "content": content[line_start:line_end].strip()[:100],
        })
